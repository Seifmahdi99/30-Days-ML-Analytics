{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas_profiling as pp\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,8)  #Adjusts the configuration of the plots we will create\n",
    "\n",
    "\n",
    "\n",
    "#Read in the Data\n",
    "\n",
    "df1= pd.read_csv(r'C:\\Users\\Amr_M\\Downloads\\Portfolio Projects\\Project 5\\test.csv')\n",
    "df2= pd.read_csv(r'C:\\Users\\Amr_M\\Downloads\\Portfolio Projects\\Project 5\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the test.csv\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the train.csv\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the info and data types of test.csv\n",
    "df1.info()\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the info and data types of train.csv\n",
    "df2.info()\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the summary of test.csv\n",
    "\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the summary of test.csv\n",
    "\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Auto EDA using Pandas_Profiling for test.csv\n",
    "pp.ProfileReport(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Auto EDA using Pandas_Profiling for train.csv\n",
    "pp.ProfileReport(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start looking at correlation of the test.csv\n",
    "\n",
    "df1.corr(method = 'pearson') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start looking at correlation of the train.csv\n",
    "\n",
    "df2.corr(method = 'pearson') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium Positive Correlations in test.csv\n",
    "correlate = df1.corr(method = 'pearson') \n",
    "correlate[correlate >= 0.4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium Positive Correlations in train.csv\n",
    "correlate2 = df2.corr(method = 'pearson') \n",
    "correlate2[correlate2 >= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak  Positive Correlations in test.csv\n",
    "correlate3 = df1.corr(method = 'pearson') \n",
    "correlate3[correlate3 >= 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak  Positive Correlations in train.csv\n",
    "correlate4 = df2.corr(method = 'pearson') \n",
    "correlate4[correlate4 >= 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak  Negative Correlations in test.csv\n",
    "correlate4 = df1.corr(method = 'pearson') \n",
    "correlate4[correlate4 <= -0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak  Negative Correlations in train.csv\n",
    "correlate5 = df2.corr(method = 'pearson') \n",
    "correlate5[correlate5 <= -0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix of test.csv\n",
    "\n",
    "correlation_matrix1 = df1.corr(method = 'pearson')\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "\n",
    "plt.title(\"Correlation Matrix to show the correlation between all the numeric variables\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix of train.csv\n",
    "\n",
    "correlation_matrix2 = df2.corr(method = 'pearson')\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "\n",
    "plt.title(\"Correlation Matrix to show the correlation between all the numeric variables\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this to more accurately extract corr\n",
    "corr_pairs1=correlation_matrix1.unstack()\n",
    "corr_pairs1.sort_values()\n",
    "corr_pairs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting corr from test.csv\n",
    "moderatecorr1 = corr_pairs1[(corr_pairs1) > 0.4]\n",
    "\n",
    "moderatecorr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this to more accurately extract corr\n",
    "corr_pairs2=correlation_matrix1.unstack()\n",
    "corr_pairs2.sort_values()\n",
    "corr_pairs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting corr from train.csv\n",
    "moderatecorr2 = corr_pairs2[(corr_pairs2) > 0.4]\n",
    "\n",
    "moderatecorr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using factorize - this assigns a random numeric value for each unique categorical value for the test.csv\n",
    "\n",
    "df1.apply(lambda x: x.factorize()[0]).corr(method='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using factorize - this assigns a random numeric value for each unique categorical value for the train.csv\n",
    "\n",
    "df2.apply(lambda x: x.factorize()[0]).corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix3 = df1.apply(lambda x: x.factorize()[0]).corr(method='pearson')\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot = True)\n",
    "\n",
    "plt.title(\"Correlation matrix for all the columns in test.csv\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix4 = df2.apply(lambda x: x.factorize()[0]).corr(method='pearson')\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot = True)\n",
    "\n",
    "plt.title(\"Correlation matrix for all the columns in train.csv\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
